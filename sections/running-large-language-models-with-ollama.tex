\section{Running Large Language Models with Ollama}

\noindent \textbf{Video}: \href{https://www.youtube.com/watch?v=nNxtQhz1b2M}{\textbf{\color{blue}Raspberry Pi 5 AI Setup Guide: Run DeepSeek, TinyLlama +more LOCALLY!}} (Channel: \href{https://www.youtube.com/@WagnersTechTalk}{\textbf{\color{blue}Wagner's TechTalk}})

\vspace{0.5cm}

\noindent \textbf{Operating System}: Raspberry Pi OS Lite (64-bit), remote connection.

\vspace{0.5cm}

\noindent \textbf{Steps:}
\begin{enumerate}
\item Prepare the system and install Ollama:
\begin{lstlisting}[language=bash, breaklines=true, breakatwhitespace=true, columns=fullflexible]
$ sudo apt update && sudo apt upgrade -y
$ curl -fsSL https://ollama.com/install.sh | sh
\end{lstlisting}

\item Run the \texttt{tinyllama} large language model:

\begin{lstlisting}[language=bash, breaklines=true, breakatwhitespace=true, columns=fullflexible]
$ ollama run tinyllama
\end{lstlisting}

The first run takes more time as it downloads the model. Later runs start faster.

\item Interact with the model by typing a question and pressing \texttt{ENTER}. To exit, type:
\begin{lstlisting}[language=bash, breaklines=true, breakatwhitespace=true, columns=fullflexible]
$ /bye
\end{lstlisting}

\end{enumerate}

\noindent \textbf{Optional Enhancements:}
\begin{itemize}
\item Explore additional models on the \href{https://ollama.com/search}{\textbf{\color{blue}Ollama Model Search}} page. For example, to launch DeepSeek (a lightweight option), use the following command:  
\begin{lstlisting}[language=bash, breaklines=true, breakatwhitespace=true, columns=fullflexible]
$ ollama run deepseek-r1:1.5b
\end{lstlisting}

\item Investigate Ollama commands and model management:

Use the following commands to interact with Ollama:
\begin{itemize}
\item \texttt{/show} – Display model details
\item \texttt{/load <model>} – Load a model or session
\item \texttt{/save <model>} – Save the current session
\item \texttt{/clear} – Reset the session
\item \texttt{/bye} – Exit Ollama
\item \texttt{/help} – Display help
\end{itemize}

For model management, list installed models:
\begin{lstlisting}[language=bash, breaklines=true, breakatwhitespace=true, columns=fullflexible]
$ ollama list
\end{lstlisting}

Command for removing a model:
\begin{lstlisting}[language=bash, breaklines=true, breakatwhitespace=true, columns=fullflexible]
$ ollama rm <model>
\end{lstlisting}

Commands to uninstall Ollama:
\begin{lstlisting}[language=bash, breaklines=true, breakatwhitespace=true, columns=fullflexible]
$ sudo systemctl stop ollama
$ sudo systemctl disable ollama
$ sudo rm /etc/systemd/system/ollama.service
\end{lstlisting}

\end{itemize}